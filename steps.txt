*1. screenshots for map item detection ( roboflow)
*2. screenshots for menu item detection ( roboflow )
*3. manual annotation of screenshots ( oooooooooooffffffff)
*3. train image collection ( yolov8)
#4. determine map and menu navigation options (yolov8)
#5. ocr for image -> text for menu navigation (easyOCR)
6. set up dictionary to send to LLM from image detection models and menu navigation options
7. send map as message to llm ( ollama backend would be easiest)
8. get response from llm to navigate map and select options ( pygame/pyautogui)
8. sytem prompt switching to change goal
9. keep track of attacks used for positive and negative outcomes (sqllite - write to DB)
10. add attack outcomes to context for battle menu for learning battles ( sqlilte - read from DB + ollama)
